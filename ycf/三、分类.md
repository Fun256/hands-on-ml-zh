准确率：预测正确的个数， 一共100个中，预测正确的个数

召唤率：在全部中，能检测出的数量，一共有100个，预测为A 的数量

分类问题中，PR 曲线 和 ROC 曲线都考虑对比下， 大部分情况下县使用 ROC AUC 曲线就够了

画 ROC AUC 曲线
```python
y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class
fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)
```
一个分类器被训练好了之后，它会保存目标类别列表到它的属性classes_ 中去

### 多类分类
OVA：一对多，会训练多个分类器，然后让每一个分类器对这个图片进行分类，选出决策分数最高的那个分类器
OVO：一对一，一个分类器用来处理数字 0 和数字 1，一个用来处理数字 0 和数字 2，一个用来处理数字 1 和 2，以此类推。当你想对一张图片进行分类，
你必须将这张图片跑在全部45个二分类器上。然后看哪个类胜出。
OvO 策略的主要优点是：每个分类器只需要在训练集的部分数据上面进行训练。这部分数据是它所需要区分的那两个类对应的数据。

对于大部分的二分类器来说，OvA 是更好的选择。

如果你想强制 Scikit-Learn 使用 OvO 策略或者 OvA 策略，你可以使用OneVsOneClassifier类或者OneVsRestClassifier类。创建一个样例，传递一个二分类器给它的构造函数。
举例子，下面的代码会创建一个多类分类器，使用 OvO 策略，基于SGDClassifier。
```python3 
>>> from sklearn.multiclass import OneVsOneClassifier
>>> ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))
>>> ovo_clf.fit(X_train, y_train)
>>> ovo_clf.predict([some_digit])
array([ 5.])
>>> len(ovo_clf.estimators_)
45
```

你可以调用predict_proba()，得到样例对应的类别的概率值的列表：
```python3
>>> forest_clf.predict_proba([some_digit])
array([[ 0.1, 0. , 0. , 0.1, 0. , 0.8, 0. , 0. , 0. , 0. ]])
```

现在当然你想评估这些分类器。像平常一样，你想使用交叉验证。让我们用cross_val_score()来评估SGDClassifier的精度。
```python3
>>> cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring="accuracy")
array([ 0.84063187, 0.84899245, 0.86652998])
```

###  误差分析
探索准备数据的候选方案，尝试多种模型，把最好的几个模型列为入围名单，用GridSearchCV调试超参数，尽可能地自动化

我们假设你已经找到一个不错的模型，你试图找到方法去改善它。一个方式是分析模型产生的误差的类型。

```python3
>>> y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)
>>> conf_mx = confusion_matrix(y_train, y_train_pred)

plt.matshow(conf_mx, cmap=plt.cm.gray)
plt.show()
```
行代表实际类别，列代表预测的类别

我们关注仅包含误差数据的图像呈现。首先你需要将混淆矩阵的每一个值除以相应类别的图片的总数目。
这样子，你可以比较错误率，而不是绝对的错误数（这对大的类别不公平）。

```python
row_sums = conf_mx.sum(axis=1, keepdims=True)
norm_conf_mx = conf_mx / row_sums
```
现在让我们用 0 来填充对角线。这样子就只保留了被错误分类的数据。让我们画出这个结果。
```python
np.fill_diagonal(norm_conf_mx, 0)
plt.matshow(norm_conf_mx, cmap=plt.cm.gray)
plt.show()
```
![](https://github.com/Fun256/hands-on-ml-zh/blob/dev/images/chapter_3/chapter3.9.jpeg)

现在你可以清楚看出分类器制造出来的各类误差。记住：行代表实际类别，列代表预测的类别。第 8、9 列相当亮，这告诉你许多图片被误分成数字 8 或者数字 9。
相似的，第 8、9 行也相当亮，告诉你数字 8、数字 9 经常被误以为是其他数字。相反，一些行相当黑，比如第一行：这意味着大部分的数字 1 被正确分类
（一些被误分类为数字 8 ）。留意到误差图不是严格对称的。举例子，比起将数字 8 误分类为数字 5 的数量，有更多的数字 5 被误分类为数字 8。

分析混淆矩阵通常可以给你提供深刻的见解去改善你的分类器。回顾这幅图，看样子你应该努力改善分类器在数字 8 和数字 9 上的表现，和纠正 3/5 的混淆。
举例子，你可以尝试去收集更多的数据，或者你可以构造新的、有助于分类器的特征。举例子，写一个算法去数闭合的环（比如，数字 8 有两个环，数字 6 有一个， 5 没有）。
又或者你可以预处理图片（比如，使用 Scikit-Learn，Pillow， OpenCV）去构造一个模式，比如闭合的环。

### 多标签分类
输出多个二值标签的分类系统被叫做多标签分类系统。
比方说，这个分类器被训练成识别三个人脸，Alice，Bob，Charlie；然后当它被输入一张含有 Alice 和 Bob 的图片，它应该输出[1, 0, 1]
（意思是：Alice 是，Bob 不是，Charlie 是）。

```python
from sklearn.neighbors import KNeighborsClassifier
y_train_large = (y_train >= 7)
y_train_odd = (y_train % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)
```
这段代码创造了一个y_multilabel数组，里面包含两个目标标签。第一个标签指出这个数字是否为大数字（7，8 或者 9），第二个标签指出这个数字是否是奇数。
接下来几行代码会创建一个KNeighborsClassifier样例（它支持多标签分类，但不是所有分类器都可以），然后我们使用多目标数组来训练它。
现在你可以生成一个预测，然后它输出两个标签：
```python
>>> knn_clf.predict([some_digit])
array([[False, True]], dtype=bool)
```
它工作正确。数字 5 不是大数（False），同时是一个奇数（True）。









